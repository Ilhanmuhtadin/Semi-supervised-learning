{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc97eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Bagi data menjadi data dilabeli dan tidak dilabeli\n",
    "X_labeled, X_unlabeled, y_labeled, _ = train_test_split(X, y, test_size=0.9, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6814d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.006787330316742082\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model SVM\n",
    "classifier = SVC(kernel='linear')\n",
    "\n",
    "# Latih model awal dengan data dilabeli\n",
    "classifier.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Prediksi kelas untuk data tidak dilabeli\n",
    "predicted_labels = classifier.predict(X_unlabeled)\n",
    "\n",
    "# Tambahkan data yang diprediksi dengan tingkat kepercayaan tertentu ke dalam data dilabeli\n",
    "threshold = 0.5\n",
    "X_labeled = np.vstack([X_labeled, X_unlabeled])\n",
    "y_labeled = np.hstack([y_labeled, predicted_labels])\n",
    "\n",
    "# Latih ulang model dengan data baru\n",
    "classifier.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Evaluasi model\n",
    "X_test, y_test = diabetes.data, diabetes.target\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8374bab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65b5481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113., 134., 113., 134., 134., 134., 134., 113., 113., 134., 134.,\n",
       "       113., 134., 113., 134., 200., 113., 113., 134., 134., 134., 134.,\n",
       "       134., 113., 134., 134., 134., 134., 134., 113., 134., 134., 113.,\n",
       "       134., 134., 134., 113., 134., 113., 134., 113., 134., 134., 134.,\n",
       "       113., 113., 134., 134., 134., 113., 113., 113., 134., 113., 134.,\n",
       "       134., 134., 134., 134., 113., 134., 113., 134., 134., 134., 113.,\n",
       "       113., 113., 134., 134., 134., 113., 113., 113., 113., 113., 113.,\n",
       "       134., 134., 134., 113., 113., 134., 134., 134., 134., 134., 134.,\n",
       "       134., 134., 134., 113., 113., 134., 134., 134., 113., 113., 134.,\n",
       "       134., 113., 113., 134., 113., 134., 134., 134., 113., 113., 113.,\n",
       "       134., 134., 134., 113., 113., 200., 113., 113., 113., 134., 134.,\n",
       "       113., 113., 200., 134., 113., 134., 134., 134., 113., 113., 134.,\n",
       "       113., 134., 134., 113., 134., 113., 113., 113., 113., 200., 113.,\n",
       "       134., 113., 113., 113., 113., 134., 113., 113., 134., 113., 113.,\n",
       "       113., 113., 134., 113., 134., 113., 134., 200., 134., 113., 134.,\n",
       "       134., 134., 113., 113., 113., 134., 134., 113., 134., 134., 134.,\n",
       "       113., 113., 134., 113., 113., 134., 113., 113., 113., 113., 200.,\n",
       "       134., 113., 134., 113., 134., 134., 113., 134., 113., 134., 113.,\n",
       "       134., 113., 134., 134., 113., 113., 113., 113., 113., 113., 113.,\n",
       "       113., 134., 113., 113., 134., 134., 113., 200., 113., 134., 134.,\n",
       "       134., 134., 113., 134., 134., 113., 134., 113., 134., 134., 200.,\n",
       "       113., 113., 134., 113., 113., 113., 134., 113., 113., 113., 113.,\n",
       "       134., 134., 134., 134., 134., 134., 200., 113., 113., 200., 113.,\n",
       "       113., 113., 134., 113., 134., 113., 113., 134., 113., 113., 134.,\n",
       "       113., 113., 134., 113., 113., 134., 113., 113., 134., 113., 113.,\n",
       "       113., 113., 134., 113., 134., 113., 134., 113., 134., 113., 113.,\n",
       "       134., 113., 113., 200., 113., 113., 134., 113., 134., 134., 134.,\n",
       "       134., 134., 113., 113., 113., 113., 113., 113., 134., 113., 113.,\n",
       "       134., 113., 113., 113., 134., 113., 134., 134., 113., 113., 113.,\n",
       "       113., 200., 113., 113., 113., 113., 200., 113., 113., 134., 134.,\n",
       "       113., 134., 113., 113., 134., 134., 200., 113., 134., 134., 113.,\n",
       "       113., 113., 113., 134., 113., 200., 134., 134., 134., 113., 134.,\n",
       "       134., 134., 113., 113., 134., 113., 134., 113., 113., 134., 113.,\n",
       "       113., 113., 113., 113., 113., 113., 113., 134., 113., 134., 134.,\n",
       "       134., 113., 200., 113., 113., 134., 113., 134., 113., 134., 113.,\n",
       "       113., 134., 134., 113., 134., 113., 134., 113., 134., 113., 134.,\n",
       "       134., 113., 134., 113., 113., 134., 113., 113., 113., 113., 134.,\n",
       "       113., 113., 113., 113., 134., 113., 134., 113., 113., 113., 134.,\n",
       "       134., 134., 113., 113., 113., 113., 113., 134., 113., 134., 113.,\n",
       "       134., 134., 113., 113., 134., 113., 134., 134., 113., 113., 113.,\n",
       "       113., 134.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef9b102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial model accuracy: 0.09954751131221719\n",
      "Iteration 1 accuracy: 0.8823529411764706\n",
      "Iteration 2 accuracy: 0.9004524886877828\n",
      "Iteration 3 accuracy: 0.9004524886877828\n",
      "Iteration 4 accuracy: 0.8981900452488688\n",
      "Iteration 5 accuracy: 0.9004524886877828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "\n",
    "# Bagi data menjadi data dilabeli dan tidak dilabeli\n",
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Inisialisasi model Random Forest\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fungsi untuk memperbarui dataset dilabeli dengan memilih sampel yang paling tidak pasti (Uncertainty Sampling)\n",
    "def query_instances(model, X_pool, n_instances=10):\n",
    "    uncertainty = -model.predict_proba(X_pool).max(axis=1)\n",
    "    idx = np.argsort(uncertainty)[:n_instances]\n",
    "    return X_pool[idx], idx\n",
    "\n",
    "# Fungsi untuk menambahkan sampel baru ke dataset dilabeli\n",
    "def update_labeled_dataset(X_pool, y_pool, X_new, y_new, idx):\n",
    "    X_pool = np.delete(X_pool, idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, idx)\n",
    "    X_labeled = np.vstack([X_new, X_pool])\n",
    "    y_labeled = np.hstack([y_new, y_pool])\n",
    "    return X_labeled, y_labeled\n",
    "\n",
    "# Latih model awal dengan data dilabeli\n",
    "classifier.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Evaluasi model awal\n",
    "X_test, y_test = diabetes.data, diabetes.target\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Initial model accuracy:\", accuracy)\n",
    "\n",
    "# Iterasi active learning\n",
    "n_iterations = 5\n",
    "for i in range(n_iterations):\n",
    "    # Prediksi kelas untuk data tidak dilabeli dan pilih sampel yang paling tidak pasti\n",
    "    X_pool, idx = query_instances(classifier, X_unlabeled)\n",
    "    y_pool = classifier.predict(X_pool)\n",
    "\n",
    "    # Tambahkan sampel yang dipilih ke dalam dataset dilabeli\n",
    "    X_labeled, y_labeled = update_labeled_dataset(X_unlabeled, y_unlabeled, X_pool, y_pool, idx)\n",
    "\n",
    "    # Latih ulang model dengan data baru\n",
    "    classifier.fit(X_labeled, y_labeled)\n",
    "\n",
    "    # Evaluasi model\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Iteration {i+1} accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af01e4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into labeled and unlabeled sets\n",
    "X_labeled, X_unlabeled, y_labeled, _ = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_labeled = scaler.fit_transform(X_labeled)\n",
    "X_unlabeled = scaler.transform(X_unlabeled)\n",
    "\n",
    "# Initialize base classifier (k-NN)\n",
    "base_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Initialize self-training classifier\n",
    "self_training_clf = SelfTrainingClassifier(base_classifier)\n",
    "\n",
    "# Fit the self-training classifier on labeled and unlabeled data\n",
    "self_training_clf.fit(X_labeled, y_labeled)\n",
    "\n",
    "# Predict on the unlabeled data\n",
    "pseudo_labels = self_training_clf.predict(X_unlabeled)\n",
    "\n",
    "# Incorporate pseudo-labels into labeled set\n",
    "X_pseudo_labeled = X_unlabeled\n",
    "y_pseudo_labeled = pseudo_labels\n",
    "\n",
    "# Retrain the classifier on the combined labeled data\n",
    "X_combined = np.vstack((X_labeled, X_pseudo_labeled))\n",
    "y_combined = np.concatenate((y_labeled, y_pseudo_labeled))\n",
    "self_training_clf.fit(X_combined, y_combined)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = self_training_clf.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b3c63",
   "metadata": {},
   "source": [
    "### sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b774aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics,datasets,semi_supervised,svm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into labeled and unlabeled sets\n",
    "X_labeled, X_unlabeled, y_labeled,y_hide = train_test_split(X, y, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4a43cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0,\n",
       "       0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 0, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0,\n",
       "       0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0,\n",
       "       2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hh=np.concatenate([y_labeled,y_hide])\n",
    "y_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4f83a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  1,  0,  1,  2,  0,  0,  1,  1,  0,  2,  0,  0,  1,  1,  2,\n",
       "        1,  2,  2,  1,  0,  0,  2,  2,  0,  0,  0,  1,  2,  0,  2,  2,  0,\n",
       "        1,  1,  2,  1,  2,  0,  2,  1,  2,  1,  1,  1,  0,  1,  1,  0,  1,\n",
       "        2,  2,  0,  1,  2,  2,  0,  2,  0,  1,  2,  2,  1,  2,  1,  1,  2,\n",
       "        2,  0,  1,  2,  0,  1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hh=np.concatenate([y_labeled,y_hide])\n",
    "y_hh\n",
    "X_new=np.concatenate([X_labeled,X_unlabeled])\n",
    "y_new=np.concatenate([y_labeled,y_unlabeled])\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52e7e461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 2, 2, 1, 0,\n",
       "       0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0,\n",
       "       0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0,\n",
       "       2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC(probability=True)\n",
    "lbl=semi_supervised.SelfTrainingClassifier(svc)\n",
    "lbl.fit(X_new,y_new)\n",
    "lbl.predict(X_new)\n",
    "\n",
    "\n",
    "lbl=semi_supervised.LabelPropagation()\n",
    "lbl.fit(X_new,y_new)\n",
    "lbl.predict(X_new)\n",
    "\n",
    "lbl=semi_supervised.LabelSpreading()\n",
    "lbl.fit(X_new,y_new)\n",
    "lbl.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1f5fb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(lbl.predict(X_new),y_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f007afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0,\n",
       "       0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 0, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0,\n",
       "       0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0,\n",
       "       2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl=semi_supervised.LabelPropagation()\n",
    "lbl.fit(X_new,y_new)\n",
    "lbl.predict(X_new)\n",
    "\n",
    "lbl=semi_supervised.LabelSpreading()\n",
    "lbl.fit(X_new,y_new)\n",
    "lbl.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "694f0fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(lbl.predict(X_new),y_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbda7987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0,\n",
       "       0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1,\n",
       "       1, 2, 2, 0, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0,\n",
       "       0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0,\n",
       "       2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0,\n",
       "       0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl=semi_supervised.LabelSpreading()\n",
    "lbl.fit(X_new,y_new)\n",
    "lbl.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4678215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(lbl.predict(X_new),y_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a35d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n",
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('clf',\n",
       "                 SelfTrainingClassifier(base_estimator=SVC(C=10, gamma=0.1,\n",
       "                                                           probability=True)))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics,datasets,semi_supervised,svm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into labeled and unlabeled sets\n",
    "X_labeled, X_unlabeled, y_labeled,y_hide = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "y_hh=np.concatenate([y_labeled,y_hide])\n",
    "\n",
    "\n",
    "X_new=np.concatenate([X_labeled,X_unlabeled])\n",
    "y_new=np.concatenate([y_labeled,y_unlabeled])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SelfTrainingClassifier(SVC(probability=True)))\n",
    "])\n",
    "\n",
    "# Define parameter grid for SVC\n",
    "param_grid = {'clf__base_estimator__C': [0.1, 1, 10], 'clf__base_estimator__gamma': [0.1, 0.01, 0.001]}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_labeled, y_labeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80d4deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\_self_training.py:210: UserWarning: y contains no unlabeled samples\n",
      "  warnings.warn(\"y contains no unlabeled samples\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('clf',\n",
       "                 SelfTrainingClassifier(base_estimator=SVC(C=10, gamma=0.1,\n",
       "                                                           probability=True)))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on the unlabeled data\n",
    "pseudo_labels = pipeline.predict(X_unlabeled)\n",
    "\n",
    "# Incorporate pseudo-labels into labeled set\n",
    "X_pseudo_labeled = X_unlabeled\n",
    "y_pseudo_labeled = pseudo_labels\n",
    "\n",
    "# Retrain the classifier on the combined labeled data\n",
    "X_combined = np.vstack((X_labeled, X_pseudo_labeled))\n",
    "y_combined = np.concatenate((y_labeled, y_pseudo_labeled))\n",
    "pipeline.fit(X_combined, y_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89d388bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "y_pred = pipeline.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbcfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
